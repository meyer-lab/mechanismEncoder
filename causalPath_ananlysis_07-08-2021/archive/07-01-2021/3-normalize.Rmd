---
title: 'Normalize Data (in CausalPath Format)'
author: "Will Yashar"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    number_sections: no
    theme: lumen
    toc: yes
    toc_float:
      collapsed: yes
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Packages
```{r}
library(tidyverse)
library(naniar)
library(VIM)
library(missMDA)
library(ggbiplot)
library(ggthemes)
library(quantable)
library(factoextra)
```

# Load data

```{r}
cp_format_file <- "aml_data_cp_format_unnormalized.tsv"
data <- read.table(file = cp_format_file, sep = "\t", header = TRUE, check.names = FALSE)
```

# Pre-Normalization PCA
# Sparse PCA workflow: http://juliejosse.com/wp-content/uploads/2018/05/DataAnalysisMissingR.html#regression_with_na_(quantitative)
# PCA workflow: https://www.datacamp.com/community/tutorials/pca-analysis-r

```{r}
# Custom PCA Function
sparse_pca <- function(data, data_type) {
  
  print(sprintf("PCA analysis for the %s data", data_type))
  
  # Extract sample values
  sample_vals <- data[,5:ncol(data)]
  
  # Visualize missing values (# of missing values)
  print("Visualising missing values")
  gg_miss_var(sample_vals, show_pct = TRUE)
  ggsave(file = sprintf("results/%s_percent_missing_values.png", data_type), dev = "png")
  
  # Impute dataset in preparation for PCA
  print("Imputing dataset")
  #sample_vals <- sample_vals[,1:5]
  imputed <- imputePCA(sample_vals, ncp = 2, scale = FALSE)
  write.table(imputed$completeObs, file = sprintf("results/%s_imputed.tsv", data_type), sep = "\t", row.names = FALSE, quote = FALSE)
  
  # Perform PCA
  print("Calculating principle components")
  pca <- prcomp(imputed$completeObs, center = TRUE, scale. = TRUE)
  
  # Percent of variance explained
  fviz_eig(pca, addlabels = TRUE)
  ggsave(file = sprintf("results/%s_pca_percent_variance_explained.png", data_type), dev = "png")

  # Visualize PCA
  print("Graphing PCA")
  ggbiplot(pca, 
           ellipse = TRUE, 
           var.axes= FALSE, 
           obs.scale = 1, 
           var.scale = 1, 
           alpha = 0.3,
           circle = TRUE) + 
    theme_clean()
  ggsave(file = sprintf("results/%s_pca.png", data_type), dev = "png")
  
}
```

# Pre-Normalization PCA
```{r}
sparse_pca(data, "unnormalized")
```

# Column Normalize

```{r}
# Column normalize
data_col_norm <- robustscale(data[,5:ncol(data)], dim = 2, center = TRUE, scale = TRUE, preserveScale = TRUE)
data_col_norm$data[is.na(data_col_norm$data)] <- NaN
data_col_norm <- cbind(data[,1:4], data_col_norm$data)

# Post-normalization PCA
# Datasets are too large to run PCA methods locally
# sparse_pca(data_col_norm, "col-normalized")
write.table(data_col_norm, file = "aml_data_cp_format_col_norm.tsv", sep = "\t", row.names = FALSE, quote = FALSE)
```

# Row Normalize

```{r}
# Row normalize 
data_row_norm <- robustscale(data[,5:ncol(data)], dim = 1, center = TRUE, scale = TRUE, preserveScale = TRUE)
data_row_norm$data[is.na(data_row_norm$data)] <- NaN
data_row_norm <- cbind(data[,1:4], data_row_norm$data)

# Post-normalization PCA
# Datasets are too large to run PCA methods locally
# sparse_pca(data_row_norm, "row-normalized")
write.table(data_row_norm, file = "aml_data_cp_format_row_norm.tsv", sep = "\t", row.names = FALSE, quote = FALSE)
```

# Session Information

```{r}
sessionInfo()
```